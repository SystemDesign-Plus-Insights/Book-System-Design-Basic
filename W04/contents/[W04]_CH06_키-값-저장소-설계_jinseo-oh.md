## 개요

키-값 쌍에서 키는 일반 텍스트일 수도 있고 해시 값일 수도 있다. 성능상의 이유로, 키는 짧을수록 좋다. 키-값 쌍에서 값은 문자열일 수도 있고 리스트일 수도 있고 객체일 수도 있다. 

키-값 저장소로 널리 알려진 것으로는 

- 아마존 다이나모
- memcached
- redis

등이 있다.

이번 장에서는 다음 연산을 지원하는 키-값 저장소를 설계한다.

- put(key, value): 키-값 쌍을 저장소에 저장한다.
- get(key): 인자로 주어진 키에 매달린 값을 꺼낸다.

## 문제 이해 및 설계 범위

다음 특성을 갖는 키-값 저장소를 설계한다.

- 키-값 쌍의 크기는 10KB 이하이다.
- 큰 데이터를 저장할 수 있어야 한다.
- 높은 가용성을 제공해야 한다. 따라서 시스템은 설사 장애가 있더라도 빨리 응답해야 한다.
- 높은 규모 확장성을 제공해야 한다. 따라서 트래픽 양에 따라 자동적으로 서버 증설/삭제가 이루어져야 한다.
- 데이터 일관성 수준은 조정이 가능해야 한다.
- 응답 지연시간(latency)이 짧아야 한다.

## 단일 서버 키-값 저장소

키-값 쌍 전부를 해시 테이블로 저장하면 속도는 빠르지만, 모든 데이터를 메모리 안에 두는 것이 불가능하다.

이 문제를 해결하기 위한 개선책은 다음과 같다.

- 데이터 압축(compression)
- 자주 쓰이는 데이터만 메모리에 두고 나머지는 디스크에 저장

이렇게 개선한다고 해도, 한 대 서버로 부족한 때가 찾아온다.

많은 데이터를 저장하려면 분산 키-값 저장소(distributed key-value store)를 만들 필요가 있다.

## 분산 키-값 저장소

분산 해시 테이블이라고도 불린다. 키-값 쌍을 여러 서버에 분산 시키는 탓이다. 

### CAP 정리(Consistency, Availability, Partition Tolerance thorem)

분산 시스템을 설계할 때는 CAP 정리를 이해하고 있어야 한다.

- **일관성 (consistency)**
    - 어떤 노드에 접속했느냐에 관계없이 언제나 같은 데이터를 보게 되어야 한다.
- **가용성 (availability)**
    - 일부 노드에 장애가 발생하더라도 항상 응답을 받을 수 있어야 한다.
- **파티션 감내 (partition tolerance)**
    - `파티션`은 두 노드 사이에 통신 장애가 발생하였음을 의미한다.
    - 파티션 감내는 네트워크에 파티션이 생기더라도 시스템은 계속 동작하여야 한다는 것을 뜻한다.
    

CAP 정리는 이들 가운데 어떤 두 가지를 충족하려면 나머지 하나는 반드시 희생되어야 한다는 것을 의미한다.

![image](https://github.com/SystemDesign-Plus-Insights/Book-System-Design-Basic/assets/62508156/640ead10-dc89-47d7-9c61-8f91c3aaf291)


- CP 시스템 (HBase, MongoDB)
    - 일관성과 파티션 감내를 지원하는 키-값 저장소
    - 은행 거래 시스템
    - 주문이 일관되게 처리해야 하는 전자 상거래 시스템
- AP 시스템 (Cassandra)
    - 가용성과 파티션 감내를 지원하는 키-값 저장소
    - SNS, DNS, 캐시 시스템
    

분산 시스템은 반드시 파티션 문제를 감내할 수 있도록 설계되어야 한다. 따라서 실세계에 CA 시스템은 존재하지 않는다.

![image](https://github.com/SystemDesign-Plus-Insights/Book-System-Design-Basic/assets/62508156/d3a981e1-5aa9-435c-9ee7-40afaad0c968)

위 그림은 n3에 장애가 발생하여 n1 및 n2와 통신할 수 없는 상황이다.

- **가용성 대신 일관성을 선택한다면(CP 시스템)**:
    - 일관성 불일치 문제를 피하기 위해 n1과 n2에 쓰기 연산을 중단시켜야 하는데, 그럼 가용성이 깨진다.
    - 은행권 시스템은 보통 데이터 일관성을 양보하지 않는다. 온라인 뱅킹 시스템이 계좌 최신 정보를 출력하지 못하면 큰 문제가 발생한다. 네트워크 파티션 때문에 일관성이 깨질 수 있는 상황이 발생하면 상황이 해결될 때까지는 오류를 반환해야 한다.
    
- **일관성 대신 가용성을 선택한 시스템(AP 시스템)**:
    - 설사 낡은 데이터를 반환할 위험이 있더라도 계속 읽기 연산을 허용해야 한다.
    - n1과 n2는 계속 쓰기 연산을 허용할 것이고, 파티션 문제가 해결된 뒤에 새 데이터를 n3에 전송할 것이다.

## 시스템 컴포넌트

### 데이터 파티션

데이터를 파티션 단위로 나눌 때는 다음 두 가지 문제를 중요하게 따져봐야 한다.

- **데이터를 여러 서버에 고르게 분산할 수 있는지**
- **노드가 추가/삭제될 때 데이터 이동을 최소화할 수 있는지**

5장에서 다룬 **안정 해시(consistent hash)**는 위 문제를 푸는 데 적합한 기술이다. 

안정 해시를 사용하여 데이터를 파티션하면 좋은 점은 다음과 같다.

- **규모 확장 자동화**: 시스템 부하에 따라 서버가 자동으로 추가되거나 삭제되도록 만들 수 있다.
- **다양성(heterogeneity)**: 각 서버의 용량에 맞게 가상 노드의 수를 조정할 수 있다. 즉, 고성능 서버는 더 많은 가상 노드를 갖도록 설정할 수 있다.

### 데이터 다중화

HA와 안정성을 확보하기 위해 데이터를 N개 서버에 **비동기적으로 다중화(replication)**할 필요가 있다. 여기서 N은 튜닝한 값이다. 

N개 서버를 선정하는 방법

![image](https://github.com/SystemDesign-Plus-Insights/Book-System-Design-Basic/assets/62508156/04228fb0-5138-4188-9c1a-e0f740812e04)

- 어떤 키를 링 위에 배치한 후, 그 지점으로부터 시계 방향으로 링을 순회하면서 만나는 첫 N개 서버에 데이터 사본을 보관하는 것이다. (N=3일때 key0은 s1,s2,s3에 저장됨)

- 가상 노드를 사용할 경우 선택한 N개의 노드가 대응되는 실제 물리 서버의 개수가 N보다 작아질 수 있음
    - 중복된 물리 서버를 선택하지 않도록 해야 한다.
- 같은 데이터 센터에 속한 노드는 문제를 동시에 겪을 가능성이 있다.
    - 안정성을 위해 데이터 사본은 다른 센터에 보관하고, 센터들은 고속 네트워크로 연결한다.

### 데이터 일관성

여러 노드에 다중화된 데이터는 적절히 동기화가 되어야 한다. 

**정족수 합의(Quorum Consensus) 프로토콜을 사용하면 읽기/쓰기 연산 모두에 일관성을 보장**할 수 있다.

* 정족수: 읽기 또는 쓰기 작업이 성공하기 위해 필요한 최소한의 응답 수

- N=사본 개수
- W=쓰기 연산에 대한 정족수.
    - 데이터를 쓰기 위해 필요한 최소한의 노드 수
    - 쓰기 연산이 성공한 것으로 간주되려면 적어도 W개의 서버로부터 쓰기 연산이 성공했다는 응답을 받아야 한다.
- R=읽기 연산에 대한 정족수. (일관된 최신의 데이터)
    - 데이터를 읽기 위해 필요한 최소한의 노드 수
    - 읽기 연산이 성공한 것으로 간주되려면 적어도 R개의 서버로부터 응답을 받아야 한다.


![image](https://github.com/SystemDesign-Plus-Insights/Book-System-Design-Basic/assets/62508156/27258616-ed75-4a69-bda4-9d8e064ce06f)

데이터가 s0, s1, s2에 다중화되는 상황을 예로 들어 살펴보자. 

- W=1의 의미는, 쓰기 연산이 성공했다고 판단하기 위해 중재자(coordinator)는 최소 한 대 서버로부터 쓰기 성공 응답을 받아야 한다는 뜻이다. 따라서 s1으로부터 성공 응답을 받았다면 s0, s2로부터 응답은 기다릴 필요가 없다.
- 중재자는 클라이언트와 노드 사이에서 proxy 역할을 한다.

**W,R,N 값을 정하는 것은 응답 지연과 데이터 일관성 사이 타협점을 찾는 과정이다.**

- W=1 / R=1인 구성의 경우 중재자는 한대 서버로부터의 응답만 받으면 되니 응답속도는 빠를 것이다.
- W나 R의 값이 1보다 큰 경우에는 시스템이 보여주는 데이터 일관성 수준은 향상될 테지만 중재자의 응답 속도는 가장 느린 서버로부터 응답을 기다려야 하므로 느려질 것이다.

W+R > N인 경우에는 강한 일관성이 보장된다. 일관성을 보증할 최신 데이터를 가진 노드가 최소 하나는 겹칠 것이기 때문이다.

- R=1, W=N: 빠른 읽기 연산에 최적화된 시스템
- W-1, R-N: 빠른 쓰기 연산에 최적화된 시스템
- W+R>N: 강한 일관성이 보장됨
- W+R ≤N: 강환 일관성이 보장되지 않음

### 일관성 모델

- 강한 일관성:
    - 모든 읽기 연산은 가장 최근 갱신된 결과를 반환한다.
    - 모든 사본에 현재 쓰기 연산의 결과가 반영될 때까지 해당 데이터에 대한 읽기/쓰기를 금지한다.
        - 이는 새로운 요청 처리가 중단될 수 있기 때문에 HA 시스템에 적합하지 않다.
- 약한 일관성:
    - 읽기 연산은 가장 최근 갱신된 결과를 반환하지 못할 수 있다.
- 결과적 일관성:
    - 약한 일관성의 한 형태로, 갱신 결과가 결국에는 모든 사본에 동기화되는 모델이다.
    - 다이나모 또는 카산드라가 결과적 일관성 모델을 택하고 있다.
    - 일시적으로 데이터 일관성이 깨질 수 있으며, 클라이언트 측에서 데이터 버전 정보를 활용해 해결해야 한다.

⇒ 정족수 합의 프로토콜을 사용하여 분산 시스템에서 데이터 일관성을 유지하려면 어떤 데이터가 최신인지 확인해야하는데, 이를 위해 데이터 버저닝과 벡터 클락을 사용한다. 

### 비 일관성 해소 기법: 데이터 버저닝

데이터 다중화는 가용성은 높아지지만 일관성은 낮아진다. 

⇒ 버저닝과 벡터 시계는 일관성 문제를 해소하기 위해 등장한 기술이다.

- 벡터 시계는 [서버, 버전]의 순서쌍을 데이터에 매단 것이다. 어떤 버전이 선행, 후행 버전인지, 아니면 다른 버전과 충돌이 있는지 판별하는데 쓰인다.
- Si는 서버 번호, vi는 버전 카운터
- [Si,vi]가 있으면 vi를 증가시킨다. 없다면 [Si,1]를 만든다.

![image](https://github.com/SystemDesign-Plus-Insights/Book-System-Design-Basic/assets/62508156/75dd7b95-b8fa-49bb-8f87-14dd46213e81)

그러나 벡터 시계를 사용해 충돌을 감지하고 해소하는 방법에는 두 가지 단점이 있다.

1. 충돌 감지 및 해소 로직이 클라이언트에 들아가야 하므로, 클라이언트 구현이 복잡해진다.
2. [서버: 버전]의 순서쌍 개수가 굉장히 빨리 늘어난다는 것이다. → 임계치 설정

### 장애 처리

**장애 감지(failure detection)**

- 분산 시스템에서는 한 대 서버가 “지금 서버 A가 죽었습니다” 라고 한다해서 장애처리 하지는 않는다.
- 보통 두 대 이상의 서버가 똑같이 서버 A의 장애를 보고해야 해당 서버에 실제로 장애가 발생했다고 간주하게 된다.

**가십 프로토콜(gossip protocol) [분산형 장애 감지 솔루션]**

- 각 노드는 멤버십 목록을 유지한다. 멤버십 목록은 각 멤버ID와 박동 카운터(heartbeat counter) 쌍의 목록이다.
- 각 노드는 주기적으로 자신의 박동 카운터를 증가시킨다.
- 각 노드는 무작위로 선정된 노드들에게 주기적으로 자기 박동 카운터 목록을 보낸다.
- 박동 카운터 목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신한다.
- 어떤 멤버의 박동 카운터 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버는 장애(offline) 상태인 것으로 간주한다.

![image](https://github.com/SystemDesign-Plus-Insights/Book-System-Design-Basic/assets/62508156/efdbe785-e1c4-4248-9be8-57fb751fc4f9)

**일시적 장애 처리**

- 엄격한 정족수 접근법:
    - 데이터 일관성을 우선시 해야하므로, 읽기와 쓰기 연산을 금지해야 한다.
- 느슨한 정족수 접근법:
    - 가용성을 우선시 한다.
    - 정족수 요구사항을 강제하는 대신, 쓰기 연산을 수행할 W개의 건강한 서버와 읽기 연산을 수행할 R개의 건강한 서버를 해시 링에서 고른다.
    - 임시 위탁 기법(hinted handoff): 느슨한 정족수 접근법에서 장애 상태인 서버로 가는 요청을 다른 노드가 대신 처리한다. 장애가 복구된 후, 데이터 일관성을 유지하도록 한다. 이를 위해 임시로 쓰기 연산을 처리한 서버에는 그에 관한 단서(hint)를 남겨둔다.

**영구적 장애 처리**

- 반-엔트로피 프로토콜(anti-entropy protocol): 영구적인 장애를 처리하고 노드 간의 데이터 일관성을 유지하기 위한 방법이다.
    - 반-엔트로피 프로토콜에서 **데이터 일관성을 검증하고, 전송 데이터를 최소화하기 위해 머클 트리를 사용**한다.

⇒ **결국 장애 노드를 삭제한다는 얘기인가?**

**머클 트리의 동작 원리**

- 리프 노드: 데이터 블록의 해시 값을 저장한다.
- 내부 노드: 자식 노드들의 해시 값을결합하여 계산된 해시 값 저장
- 루트 해시: 전체 데이터 구조의 무결성을 나타낸다.

1. 노드 장애 감지
2. 머클 트리 비교
3. 다른 데이터를 갖는 버킷들만 동기화

### 데이터 센터 장애 처리

데이터 센터 장애에 대응할 수 있는 시스템을 만들려면 **데이터를 여러 데이터 센터에 다중화하는 것이 중요**하다.

### 시스템 아키텍처

- 클라이언트: 두 가지 API get, put와 통신
- 중재자(coordinator): 키-값 저장소에 대한 프락시(proxy)역할을 하는 노드
- 노드는 안정 해시(consistent hash)의 해시 링위에 분포
- 데이터는 여러 노드에 다중화된다.
- 모든 노드가 같은 책임을 지므로, SPOF는 존재하지 않는다.

### 쓰기 경로

쓰기 요청이 특정 노드에 전달되면 무슨 일이 발생할까?(카산드라 기준)

![image](https://github.com/SystemDesign-Plus-Insights/Book-System-Design-Basic/assets/62508156/191913f1-8119-4cdd-8d04-b22c9a383e14)

1. 쓰기 요청이 커밋 로그 파일에 기록
2. 데이터가 메모리 캐시에 기록
3. 메모리 캐시가 가득차거나 임계치에 도달하면 데이터는 디스크에 있는 SSTable에 기록된다. 

SSTable은 Sorted-String Table의 약자로 <키, 값>의 순서쌍을 정렬된 리스트 형태로 관리하는 테이블이다.

### 읽기 경로

읽기 요청이 특정 노드에 전달되면 무슨일이 일어날까?(카산드라 기준)

![image](https://github.com/SystemDesign-Plus-Insights/Book-System-Design-Basic/assets/62508156/e2749186-ad67-459d-9cdf-1d6c2f417c9d)

읽기 요청을 받은 노드는 데이터가 메모리 캐시에 있는지부터 살핀다.

아래는 데이터가 메모리에 없을 때 읽기 연산이 처리되는 경로이다.

![image](https://github.com/SystemDesign-Plus-Insights/Book-System-Design-Basic/assets/62508156/2c1ed76d-bcc9-45fb-9fab-935e103936a4)

1. 데이터가 메모리 있는지 검사하고, 없으면 2로 간다.
2. 데이터가 메모리에 없으면 `불룸필터`를 검사한다.
3. 불룸 필터를 통해 어떤 SSTable에 키가 보관되어 있는지 알아낸다.
4. SSTable에서 데이터를 가져온다. 

### 요약
# Ch 4. 처리율 제한 장치의 설계

> 처리율 제한 장치(rate limiter): 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate) 제어
> 클라이언트의 요청 횟수 제한
> API 요청 횟수가 임계치를 넘으면 추가로 도달한 모든 호출은 처리가 중단됨

<br/>

### API 처리율 제한 장치의 장점

1. DoS 공격에 의한 자원 고갈 방지
   1. 우선순위가 높은 API에 더 많은 자원을 할당함
   2. 처리율 제한은 써드파티 API 에 더 많은 자원 할당이 가능
2. 비용 절감
3. 서버 과부하 방지 가능

<br/>

### Step 1. 문제 이해 및 설계 범위 확정

1. 어떤 종류?
   1. 클라이언트 측
   2. 서버 측
2. 제어 규칙
3. 시스템 규모
4. 분산 환경 동작 여부
5. 독립된 서비스 or 애플리케이션 코드 포함

<br/>

### Step 2. 개략적인 설계안 제시 및 동의 구하기

- 처리율 제한 장치는 어디에 둘 것 인가?
  - 클라이언트 : _쉽게 위변조 가능_
  - 서버
  - 미들웨어 : API로 가는 요청 통제

<br/>

![[./images/01_olive_su.png]]

- e.g. Senario 1: 초당 2개 요청으로 제한
  - 요청 2회까지는 API 서버로 전달
  - 3번째 요청부터 미들웨어에 막힘 ⇢ Status Code `429` Return

<br/>

#### API 게이트웨이

- 처리율 제한
- SSL 종단
- 사용자 인증
- IP 허용 목록 관리

<br/>

∴ 처리율 제한을 지원하는 미들웨어

<br/>

> 💡 현재 회사의 `엔지니어링 인력` / `우선순위` / `목표` 에 따라 적절하게 처리율 제한 기능을 설계한다.

- 현재 기술 스택이 서버 측 구현을 지원하기 충분할 정도로 효율이 높은지를 고민한다.
- 적절한 처리율 제한 알고리즘을 찾는다.
- 마이크로서비스에 기반 & API 게이트웨이를 설계에 이미 포함함 (사용자 인증 IP 허용 목적을 위해)
  - ⇢ 처리율 제한 기능 또한 게이트웨이에 포함시킴
- 처리율 제한 장치를 만들기에 충분한 인력이 없다면 **상용 API 게이트웨이**를 쓴다.

<br/>

# 처리율 제한 알고리즘

1. 토큰 버킷(token bucket)
2. 누출 버킷(leaky bucket)
3. 고정 윈도 카운터(fixed window counter)
4. 이동 윈도 로그(sliding window log)
5. 이동 윈도 카운터(sliding window counter)

<br/>

## 1. 토큰 버킷 알고리즘

❓토큰 버킷: 지정된 용량을 갖는 컨테이너

<br/>

- 버킷에 사전 설정된 양의 토큰이 주기적으로 채워짐
- 토큰이 꽉차면 더이상 추가 X
- 토큰 공급기(refiller): 버킷에 매초 2개의 토큰 추가
  - 버킷이 가득차면 추가로 공급된 토큰은 버림 (overflow)

<br/>

![[./images/02_olive_su.png]]

### 과정

1. 요청 도착
2. 버킷에 충분한 토큰이 있는 지 검사
   1. 충분한 토큰 O ⇢ 버킷에서 토큰 하나 꺼내고 요청을 시스템에 전달
   2. 충분한 토큰 X ⇢ 해당 요청 버림(dropped)

<br/>

![[./images/03_olive_su.png]]

- 파라미터
  - `버킷 크기`
  - `토큰 공급률`

<br/>

- 버킷 개수 (공급 제한 규칙에 종속)
  - API 엔드포인트마다 별도의 버킷을 둚 ⇢ 사용자마다
  - IP 주소별 처리율 제한 적용 ⇢ IP 주소마다
  - 시스템 처리율 제한 적용 ⇢ 모든 요청이 하나의 버킷 공유

### 장・단점

- 장점
  - 구현이 쉬움
  - 메모리 사용 측면에서 효율적임
  - 짧은 시간에 집중되는 트래픽 처리 가능
- 단점
  - `버킷 크기` , `토큰 공급률` 튜닝이 까다로움

<br/>

## 2. 누출 버킷 알고리즘

- 토큰 버킷 알고리즘과 비슷 But, 요청 처리율이 고정되어 있음
- 보통 FIFO 큐로 구현

<br/>

### 과정

![[./images/04_olive_su.png]]

1. 요청 도착
2. 큐가 가득 차있는지 봄
   1. 빈자리 O ⇢ 큐에 요청 추가
   2. 빈자리 X ⇢ 새 요청 버림
3. 지정된 시간마다 큐에서 요청 꺼내어 처리

<br/>

- 파라미터
  - `버킷 크기` (큐 사이즈): 처리될 항목 보관
  - `처리율`: 지정된 시간당 몇 개의 항목을 처리할지 (보통. 초)

<br/>

### 장・단점

- 장점
  - 큐의 크기 제한 ⇢ 메모리 사용 측면에서 효율적임
  - 고정된 처리율 ⇢ 안정적 출력이 필요한 경우 적합
- 단점
  - 트래픽이 몰릴 경우 오래된 요청이 쌓이고 **최신 요청은 버려질 수 있음**
  - `버킷 크기` , `처리율` 튜닝이 까다로움

<br/>

## 3. 고정 윈도 카운터 알고리즘

### 과정

![[./images/05_olive_su.png]]

1. 사전작업
   1. 타임라인을 고정된 간격의 윈도우로 나눈다.
   2. 각 윈도우마다 카운터를 붙인다.
2. 요청 접수
   1. 카운터 값 임계치 도달 X: 카운터 값 1 증가
   2. 카운터 값 임계치 도달 O: **새로운 요청은 새 윈도우가 열릴 때까지 버려짐**

<br/>

### 문제점

![[./images/06_olive_su.png]]

- 경계 부근에 순간적으로 많은 트래픽 집중 시, 할당량보다 더 많은 요청 처리 가능

<br/>

- e.g. 분당 최대 5개 요청 허용 시스템
  - 카운터는 매분 초기화
  - ⚠️ 몰려서 요청 접수 시, 5개를 넘어서서 10개가 처리됨

<br/>

### 장・단점

- 장점
  - 정해진 고정 처리량 ⇢ 메모리 효율 좋음
  - 이해가 쉬움
  - 특정 트래픽 패턴 처리에 적합
- 단점
  - 경계 부근에 일시적으로 많은 트래픽 인입 시, 기대치보다 많은 양의 요청을 처리할 수 있음

<br/>

## 4. 이동 윈도 로깅 알고리즘

- 고정 윈도 카운터 알고리즘의 문제점 해결

<br/>

### 과정

1. 요청 접수
2. 요청 타임스탬프 추적
   1. 보통 레디스의 정렬 집합과 같은 캐시에 보관
3. 새 요청 도착 시, 만료된(현재 윈도우 시작지점보다 오래된) 타임스탬프 제거
4. 새 요청의 타임스탬프를 로그에 추가
5. `로그 크기` ≦ `허용치` 이면 요청을 시스템에 전달
6. `로그 크기` > `허용치` 이면 처리 거부

<br/>

### 장・단점

- 장점
  - 어느 순간의 윈도우를 보더라도 허용치가 시스템 처리 한도를 넘지 않음
- 단점
  - 거부된 요청의 타임스탬프도 보관 ⇢다량의 메모리 사용

<br/>

# 4장

## 처리율 제한 장치의 설계

### 처리율 제한 장치

- 클라이언트 또는 서비스가 보내는 **트래픽의 처리율(rate)을 제어**하기 위한 장치
- **예시**
    - HTTP에서 특정 API 요청 임계치(threshold)를 넘어서면 추가로 도달한 모든 호출의 처리를 중단한다.
        - 초당 2회 이상 새글 작성 X
        - 같은 IP 주소로 하루에 10개 이상의 계성 생성 X
        - 같은 디바이스로 주당 5회 이상 리워드(reward) 요청 X

- **좋은점**
    - Dos 공격(자원 고갈) 방지
    - 비용 절감
    - 서버 과부하 방지

### 1단계. 문제 이해 및 설계 범위 확정

- 기존 2, 3장과 마찬가지로 면접은 대화하는 자리이다. 면접관과 서로 소통하며 문제를 이해하고 설계 범위를 정하자

- **요구사항**
    - 설정된 처리율을 초과하는 요청은 **정확하게 제한**한다.
    - **낮은 응답시간**: 처리율 제한 장치는 HTTP 응답시간에 나쁜 영향을 주지 않아야한다.
    - 가능한 한 적은 메모리를 써야 한다.
    - 분산형 처리율 제한: 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유할 수 있어야 한다.
    - 예외 처리: 요청이 제한되었을 때는 그 사실을 사용자에게 분명하게 알려준다.
    - 높은 결함 감내성: 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안 된다.

### 2단계. 개략적인 설계안 제시 및 동의 구하기

- 처리율 제한 장치를 어디에 두어야할까?, 클라이언트? 서버?…

- 클라이언트는 쉽게 위,변조가 가능해서 위험하다.
- 서버에 제한 장치를 둘 수 있다.
- 서버와 클라이언트 사이 미들웨어를 두어 처리할 수도 있다.

**※** **처리율 제한 장치를 어디에 두어야 할까?**

- 정답은 없다.
- 회사의 기술 스택, 상황, 우선순위, 목표
- **상황 예시**
    - 프로그래밍 언어, 캐시 서비스 등 현재 사용하고 있는 기술 스택을 점검
        - 사용하는 프로그래밍 언어가 서버 측 구현을 지원하기 충분할 정도로 효율이 높은지 확인
    - 서버에서 구현하면, **처리율 제한 알고리즘**을 알맞게 선택
    - 설계가 마이크로 서비스로 API 게이트웨이를 활용해 사용자 인증이나 IP 허용목록 관리등을 처리하고 있으면 처리율 제한 기능 또한 게이트웨이에 포함해야할 수 있다.
    - 처리율 제한 장치 구현에는 비용이 많이든다. 어려운 경우 **상용 API 게이트웨이**를 사용하는게 바람직할 수 있다.

- **처리율 제한 알고리즘**
    - **토큰 버킷 알고리즘 (아마존, 스트라이프에서 사용)**
        - 토큰 공급기에서 일정량을 토큰을 버킷에 채우고 요청에 들어오면 토큰과 함께 전달
            - 충분한 토큰이 있으면, 버킷에서 토큰과 함께 요청 전갈
            - 충분한 토큰이 없으면, 해당 요철은 버려진다. (dropped)
        - 토큰 버킷: 지정된 용량을 갖는 컨테이너
        - 토큰 공급률: 초당 몇 개의 토큰이 버킷에 공급되는가?
        - **예시**
            - 통상적으로는, API 엔드포인트마다 별도의 버킷을 둔다.
                1. 사용자마다 한 번만 포스팅
                2. 친구는 150명까지 추가 가능
                3. 좋아요 버튼은 5번까지
                
                ⇒ 총 3개의 버킷 필요
                
            - IP 주소별로 제한이 필요하면, IP 주소마다 별도의 버킷
            - 시스템 전체의 처리율을 초당 10,000개 요청으로 제한하면 모든 요청이 하나의 버킷으로 가도록 공유한다.
        - **장점**
            - 간편한 구현
            - 메모리 사용 효율적
            - 짧은 시간에 집중되는 트래픽(burst of traffic)도 처리 가능. 버킷에 토큰이 남아 있기만 하면 요청 가능하다.
        - **단점**
            - 버킷 크기와 토큰 공급률을 적절하게 튜닝하는게 어려움
    
    - **누출 버킷 알고리즘**
        - 토큰 버킷과 비슷하지만, **요청 처리율이 고정되어 있다.**
        - FIFO 큐로 구현
            - 큐에서 요청을 등록하고 일정 시간마다 요청을 처리한다.
        - 버킷 크기 = 큐의 크기
        - 처리율: 일정 시간마다 고정된 처리율
        - **장점**
            - 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적
            - 고정된 처리율로 변화없는 안정적인 요청 처리
        - **단점**
            - 트래픽이 몰릴 경우, 최신 요청들이 다수 버려지게 된다.
            - 튜닝의 어려움이 사라지진 않는다.
    
    - **고정 윈도 카운터 알고리즘**
        - 타임라인으로 고정된 간격(window)을 나누고, 각 윈도마다 카운터를 붙인다.
        - 요청이 접수될 때마다, 카운터 값은 1씩 증가
        - 카운터 값이 사전에 설정된 임계치(threshold)에 도달하면, 새로운 요청은 새로운 윈도가 열릴 때까지 버림
        - 윈도 임계치에 순간적으로 트래픽이 몰리면, 예산 임계치보다 많은 요청이 처리될 수 있다. ⇒ 처리율 제한 기능이 원하는 역할을 수행하지 못할 수 있다.
        - **장점**
            - 메모리 효율이 좋다 (정해진 간격, 임계치가 있다)
            - 트래픽 패턴에 적절히 처리 가능
        - **단점**
            - 트래픽이 특정 간격에 몰릴 경우, 기대했던 처리율 제한보다 많은 요청을 처리할 수 있다.
    
    - **이동 윈도 로깅 알고리즘**
        - 요청의 타임스탬프를 추적 (=redis, 정렬 Set 같은 캐시에 저장)
        - 새로운 요청이 오면 만료된 타임스탬프를 제거하고, 새로운 타임스탬프 로그를 추가
        - 로그의 크기 ≤ 허용치, 요청을 전달
        - 로그의 크기 > 허용치, 요청을 거부
        - **예시**
            - 허용치는 1분당 2
            1. 요청 1:00:01, 로그 (1:00:01)
            2. 요청 1:00:30 + 로그 추가 (1:00:01, 1:00:30), 로그 크기: 2 ≤ 허용치: 2 ⇒ 요청 허용 
            3. 요청 1:00:50 + 로그 추가…, 3 > 2 ⇒ 요청 거부
            4. 요청 1:01:40 + 로그 추가 ⇒ 만료된 타임스탬프 (1:00:40 이전 제거)
                
                로그 (1:00:50, 1:01:40), 2 ≤ 2 ⇒ 요청 허용 
                
        - **장점**
            - 어느 순간에도 요청 처리량이 임계치를 넘지 않는다.
        - **단점**
            - 지정된 시간 동안의 요청 타임스탬프를 모두 메모리에 저장해야 하기 때문에 메모리 사용량 높다.
    
    - **이동 윈도 카운터 알고리즘**
        - 고정 윈도 카운터 + 이동 윈도 로깅
        - 현재 1분 간의 요청 수 + 직전 1분간의 요청 수 x 이동 윈도와 직전 1분이 겹치는 비율
        - **장점**
            - 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 대응
            - 메모리 효율 좋다.
        - **단점**
            - 처리율 제한 기능이 완벽하지는 않고, 느슨하다.
    
    - **개략적인 아키텍처**
        - 기본적으로 처리율 제한 알고리즘은 동일 ⇒ 임계치(+카운터)를 두고 처리율을 제한한다.
        - 임계치를 어떻게 설정할 것인가? ⇒ 사용자 별로, ip?, API 엔드포인트나 서비스 단위로?
        - 데이터베이스는 디스크 접근으로 속도가 느리기에, 메모리 캐시를 사용하는게 좋다 ⇒ **Redis**
        - Redis는 처리율 제한 장치를 구현할 때 자주 사용
            - INCR: 메모리에 저장된 카운터의 값을 1만큼 증가
            - EXPIRE: 카운터에 타임아웃 값을 설정, 설정된 시간이 지나면 카운터는 자동으로 삭제
        - **동작원리**
            1. 클라이언트가 처리율 제한 미들웨어에게 요청을 보냄
            2. Redis의 버킷에서 카운터를 가져와 한도에 도달 했는지 검사
                1. 한도에 도달하면, 요청 거부
            3. 한도에 도달하지 않았다면 요청을 API 서버에 전달 + 미들웨어에서는 카운터 값을 증가한 후 Redis에 저장

### 3단계. 상세 설계

- 처리율 제한 규칙 어떻게 만들어지고 저장하는가?
- 처리가 제한된 요청들은 어떻게 처리되는가?
- 상세 설계 ⇒ 구체적인 설계, 성능 최적화, 모니터링

- **처리율 제한 규칙**
    
    ```
    domain: messaging
    descriptors:
    	- key: message_type
    		Value: marketing
    		rate_limit: 
    			unit: day
    			request_per_unit: 5
    ```
    

- **처리율 한도 초과 트래픽 처리**
    - HTTP 429 응답(too many request)
        - 헤더
        - X-Ratelimit-Remaining: 윈도 내에 남은 처리 가능 요청의 수
        - X-Ratelimit-Limit: 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
        - S-Ratelimit-Retry-After: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림
    - 메시지 큐에 처리 제한된 요청들을 저장해놨다가 나중에 처리 가능
    
- **분산 환경에서의 처리율 제한 장치 구현**
    - 여러 서버와 병렬 스레드를 지원하도록 확장하면 2가지 문제
        - 경쟁 조건
        - 동기화
    - **경쟁 조건**
        - 처리율 제한 장치 과정
            - 레디스에서 카운터 값을 읽는다 (counter)
            - counter + 1의 값이 임계치를 넘는지 체크
            - 넘지 않는다면, 레디스에 보관된 카운터 값을 1만큼 증가
            - 병렬로 처리하면, 원하는 count 값이 증가 되거나 체크되지 않을 수 있다.
        - 경쟁 조건의 일반적인 해결법 = **락(Lock)**
            - Lock은 시스템의 성능을 떨어뜨린다.
        - 해결책
            1. 루아 스크립트
            2. 정렬 집합 (=레디스 자료구조)
    - **동기화**
        - 처리율 제한 장치 하나만으로는 모든 요청을 처리하기 힘듦
        - 여러개의 처리율 제한 장치 서버를 구축하고 동기화 필요!
        - 해결책
            1. 고정 세션(sticky session) 활용
                - 고정 세션이란 같은 요청은 같은 곳으로 가도록 함
                - 규모면에서 확장 가능하지 않고, 유연하지 않음
            2. **레디스와 같은 중앙 집중형 데이터 저장소 사용**
                - 처리율 제한 장치의 값을 레디스에서 모아서 처리
- **성능 최적화**
    - 클라우드에서는 가장 가까운 에지 서버로 전달해 네트워크 지연을 줄인다.
    - 일관성 모델 사용?
- **모니터링**
    - 모니터링을 통해 효과적으로 처리율 제한이 일어나는지 확인
    - 처리율 제한 알고리즘이나 규칙 변경의 근거

### 4단계. 마무리

처리율 제한 알고리즘 및 규칙, 아키텍처 구조, 분산환경에서의 처리, 성능 최적화, 모니터링 확인

⇒ 더 알아볼 것

- **경성 또는 연성 처리율 제한**
    - 경성 처리율 제한: 요청의 개수는 임계치를 절대 넘을 수 없다
    - 연성 처리율 제한: 어느정도 임계치를 넘어설 수 있다.
- Application 계층 뿐만 아니라, Network 계층에서의 처리율 제한도 확인(Iptables 활용)
- 클라이언트에서의 성능 최적화
    - 클라이언트에서 캐시를 활용해 API 호출 횟수를 줄인다.
    - 처리율 제한 임계치를 이해하고, 짧은 시간 동안 너무 많은 캐시를 보내지 않도록 함
    - 예외나 에러 처리 코드 도입
    - 재시도에는 back off 시간?

### Tip

서버에서 처리율 제한 장치를 구현하기 좋은 프로그래밍 언어로는 다음과 같은 것들이 있습니다:

1. **Go (Golang)**
    - 간결하고 배우기 쉬운 문법
    - 빠른 컴파일 속도와 우수한 실행 성능
    - 동시성(Concurrency) 처리에 강점
    - 표준 라이브러리에서 rate limiting을 위한 기능 제공
2. **Python**
    - 배우기 쉽고 생산성 높은 언어
    - Flask, Django 등 웹 프레임워크 생태계 발달
    - 다양한 오픈소스 라이브러리 활용 가능 (ex. Flask-Limiter)
3. **Java**
    - 대규모 엔터프라이즈 시스템 구축에 널리 사용
    - 풍부한 오픈소스 라이브러리 활용 가능 (ex. Bucket4j, Resilience4j)
    - 장시간 실행에 강점이 있고 안정적
4. **Node.js**
    - 자바스크립트 기반으로 프론트엔드 개발자도 빠르게 학습 가능
    - 비동기 처리에 강점이 있어 높은 동시 처리 성능
    - NPM 패키지로 rate limiter 모듈 쉽게 적용 가능
5. **Rust**
    - 높은 성능과 메모리 안전성 강점
    - 동시성 처리에 매우 효과적
    - 다양한 분야에서 활용도 증가 추세